{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcae233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "project_root = Path.cwd().parents[0] # ajusta si tu notebook est√° m√°s adentro\n",
    "sys.path.append(str(project_root))\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52070aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha de ejecuci√≥n: 2025-09-10\n",
      "Usando rutas:\n",
      "- Base: C:\\Users\\EQUIPO\\Documents\\AI\\Prueba tecnica agentes\\agent_factory\\datos\n",
      "- CV: C:\\Users\\EQUIPO\\Documents\\AI\\Prueba tecnica agentes\\agent_factory\\datos\\cv\n",
      "- Daily: C:\\Users\\EQUIPO\\Documents\\AI\\Prueba tecnica agentes\\agent_factory\\datos\\daily_files\n",
      "- Feedback: C:\\Users\\EQUIPO\\Documents\\AI\\Prueba tecnica agentes\\agent_factory\\datos\\feedback\n",
      "Fuentes encontradas: 18\n",
      "Source IDs: ['195385', '195436', '195439', '196125', '199944', '207936', '207938', '209773', '211544', '220504', '220505', '220506', '224602', '224603', '228036', '228038', '239611', '239613']\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos y crear dataset\n",
    "from data_processing.data_loader import DataLoader\n",
    "from data_processing.incident_consolidator import IncidentConsolidator\n",
    "from pathlib import Path\n",
    "\n",
    "execution_date = \"2025-09-10\"\n",
    "\n",
    "# Configurar rutas expl√≠citamente para usar 'datos' en lugar de 'datos_ejemplo'\n",
    "# Desde notebooks/, subir un nivel para llegar a la ra√≠z del proyecto\n",
    "project_root = Path().resolve().parent\n",
    "datos_path = project_root / \"datos\"\n",
    "\n",
    "loader = DataLoader(\n",
    "    base_path=datos_path,\n",
    "    cv_path=datos_path / \"cv\",\n",
    "    daily_path=datos_path / \"daily_files\",\n",
    "    feedback_path=datos_path / \"feedback\"\n",
    ")\n",
    "\n",
    "source_ids = loader.get_all_source_ids()\n",
    "\n",
    "print(f\"Fecha de ejecuci√≥n: {execution_date}\")\n",
    "print(f\"Usando rutas:\")\n",
    "print(f\"- Base: {loader.base_path}\")\n",
    "print(f\"- CV: {loader.cv_path}\")\n",
    "print(f\"- Daily: {loader.daily_path}\")\n",
    "print(f\"- Feedback: {loader.feedback_path}\")\n",
    "print(f\"Fuentes encontradas: {len(source_ids)}\")\n",
    "print(f\"Source IDs: {source_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9dafc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creado con 18 fuentes\n",
      "Fuentes en dataset: ['195385', '195436', '195439', '196125', '199944', '207936', '207938', '209773', '211544', '220504', '220505', '220506', '224602', '224603', '228036', '228038', '239611', '239613']\n",
      "\n",
      "Ejemplo de fuente 195385:\n",
      "- CV disponible: True\n",
      "- Archivos del d√≠a: 7\n",
      "- Archivos semana pasada: 37\n",
      "- Incidentes detectados: ['missing', 'duplicated', 'empty', 'volume_variation', 'schedule', 'historical']\n"
     ]
    }
   ],
   "source": [
    "# Crear el dataset con todos los incidentes detectados\n",
    "consolidator = IncidentConsolidator(execution_date)\n",
    "dataset = consolidator.build_dataset(source_ids, loader)\n",
    "\n",
    "print(f\"Dataset creado con {len(dataset)} fuentes\")\n",
    "print(f\"Fuentes en dataset: {list(dataset.keys())}\")\n",
    "\n",
    "# Mostrar ejemplo de una fuente\n",
    "sample_source = list(dataset.keys())[0] if dataset else None\n",
    "if sample_source:\n",
    "    print(f\"\\nEjemplo de fuente {sample_source}:\")\n",
    "    sample_data = dataset[sample_source]\n",
    "    print(f\"- CV disponible: {'cv_text' in sample_data}\")\n",
    "    print(f\"- Archivos del d√≠a: {len(sample_data.get('daily_files', []))}\")\n",
    "    print(f\"- Archivos semana pasada: {len(sample_data.get('last_week_files', []))}\")\n",
    "    print(f\"- Incidentes detectados: {list(sample_data.get('incidents', {}).keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1e24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herramientas creadas: 3\n",
      "Nombres de herramientas: ['list_sources', 'get_source_cv_and_data', 'get_execution_date_info']\n"
     ]
    }
   ],
   "source": [
    "# Crear las herramientas para el agente\n",
    "from report_builder import build_incident_toolkit\n",
    "\n",
    "tools = build_incident_toolkit(dataset, execution_date)\n",
    "print(f\"Herramientas creadas: {len(tools)}\")\n",
    "print(f\"Nombres de herramientas: {[tool.__name__ for tool in tools]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cfbbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROBANDO HERRAMIENTAS LIMPIAS ===\n",
      "\n",
      "1. list_sources():\n",
      "{\"execution_date\": \"2025-09-10\", \"sources\": [{\"source_id\": \"195385\", \"display_name\": \"_Settlement_Layout_2\", \"files_today\": 7, \"files_last_weekday\": 37, \"expected_files\": 32, \"missing_estimate\": 25, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T08:08:36.758445+00:00\", \"last_upload_utc\": \"2025-09-10T08:08:43.241813+00:00\"}, {\"source_id\": \"195436\", \"display_name\": \"MyPal_DBR RX\", \"files_today\": 2, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T15:11:31.898388+00:00\", \"last_upload_utc\": \"2025-09-10T15:11:32.988282+00:00\"}, {\"source_id\": \"195439\", \"display_name\": \"MyPal_Activity report\", \"files_today\": 1, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T02:37:10.679913+00:00\", \"last_upload_utc\": \"2025-09-10T02:37:10.679913+00:00\"}, {\"source_id\": \"196125\", \"display_name\": \"_Settlement_Layout_1\", \"files_today\": 0, \"files_last_weekday\": 42, \"expected_files\": 37, \"missing_estimate\": 37, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"199944\", \"display_name\": \"Soop Transaction PIX 3\", \"files_today\": 2, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T11:34:06.838191+00:00\", \"last_upload_utc\": \"2025-09-10T11:34:07.927048+00:00\"}, {\"source_id\": \"207936\", \"display_name\": \"Soop - Tipo 2\", \"files_today\": 3, \"files_last_weekday\": 3, \"expected_files\": 4, \"missing_estimate\": 1, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T11:34:03.955851+00:00\", \"last_upload_utc\": \"2025-09-10T11:34:06.127244+00:00\"}, {\"source_id\": \"207938\", \"display_name\": \"Soop - Tipo 3\", \"files_today\": 3, \"files_last_weekday\": 3, \"expected_files\": 4, \"missing_estimate\": 1, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T12:13:08.784099+00:00\", \"last_upload_utc\": \"2025-09-10T12:13:10.932078+00:00\"}, {\"source_id\": \"209773\", \"display_name\": \"Desco PIX\", \"files_today\": 1, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T15:18:05.819921+00:00\", \"last_upload_utc\": \"2025-09-10T15:18:05.819921+00:00\"}, {\"source_id\": \"211544\", \"display_name\": \"Desco Devolu√ß√µes\", \"files_today\": 1, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T15:09:58.807327+00:00\", \"last_upload_utc\": \"2025-09-10T15:09:58.807327+00:00\"}, {\"source_id\": \"220504\", \"display_name\": \"__Payments_Layout_1_V3\", \"files_today\": 4, \"files_last_weekday\": 18, \"expected_files\": 15, \"missing_estimate\": 11, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T08:09:29.056047+00:00\", \"last_upload_utc\": \"2025-09-10T08:09:32.313033+00:00\"}, {\"source_id\": \"220505\", \"display_name\": \"__Payments_Layout_2_V3\", \"files_today\": 0, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 2, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"220506\", \"display_name\": \"__Payments_Layout_3_V3\", \"files_today\": 0, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 1, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"224602\", \"display_name\": \"Itm Pagamentos\", \"files_today\": 1, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T15:03:45.078930+00:00\", \"last_upload_utc\": \"2025-09-10T15:03:45.078930+00:00\"}, {\"source_id\": \"224603\", \"display_name\": \"Itm Devolu√ß√£o\", \"files_today\": 1, \"files_last_weekday\": 1, \"expected_files\": 1, \"missing_estimate\": 0, \"has_cv\": true, \"first_upload_utc\": \"2025-09-10T12:18:32.578745+00:00\", \"last_upload_utc\": \"2025-09-10T12:18:32.578745+00:00\"}, {\"source_id\": \"228036\", \"display_name\": \"WuPay_Sale payments_2\", \"files_today\": 0, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 2, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"228038\", \"display_name\": \"WuPay_STL payments_2\", \"files_today\": 0, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 2, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"239611\", \"display_name\": \"WuPay_Sale_adjustments_3\", \"files_today\": 0, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 2, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}, {\"source_id\": \"239613\", \"display_name\": \"WuPay_STL adjustments_3\", \"files_today\": 0, \"files_last_weekday\": 2, \"expected_files\": 2, \"missing_estimate\": 2, \"has_cv\": true, \"first_upload_utc\": null, \"last_upload_utc\": null}]}\n",
      "\n",
      "2. get_source_cv_and_data('195385'):\n",
      "{\n",
      "  \"source_id\": \"195385\",\n",
      "  \"execution_date\": \"2025-09-10\",\n",
      "  \"cv_text\": \"# _Settlement_Layout_2\\n\\n    ## Metadata\\n    - **Resource ID**: 195385\\n    - **Workspace ID**: 5619\\n\\n    Datasource CV: '_Settlement_Layout_2'\\n\\n  _(Based on 2332 most-recent files from 2025-06-24 ‚Üí 2025-09-16)_\\n\\n## Introducci√≥n\\n\\nThis Curriculum Vitae (CV) provides a key analysis of _Settlement_Layout_2 files behavior and patterns. The objective is to establish a baseline of normal behavior, facilitating anomaly detection and ensuring effective data flow monitoring.\\n\\n## Contents\\n  ### Statistics by source\\n1. **Filename Patterns**: Detailed analysis of file naming structure and distribution by entity.\\n\\n2. **Upload Schedule and Processing Patterns**: Comprehensive statistics on file volumes, upload schedules, and operational windows by source. It also contains information about file distribution by file status and the types of file formats the source typically receives. \\n\\n3. **Day of Week Summary...\n",
      "\n",
      "‚úÖ Toolkit limpio con 3 herramientas:\n",
      "  - list_sources\n",
      "  - get_source_cv_and_data\n",
      "  - get_execution_date_info\n"
     ]
    }
   ],
   "source": [
    "# Probar las herramientas limpias\n",
    "print(\"=== PROBANDO HERRAMIENTAS LIMPIAS ===\")\n",
    "\n",
    "# 1. list_sources\n",
    "list_sources = next(tool for tool in tools if tool.__name__ == \"list_sources\")\n",
    "print(\"\\n1. list_sources():\")\n",
    "sources_result = list_sources()\n",
    "print(sources_result)\n",
    "\n",
    "# 2. get_source_cv_and_data para la fuente 195385\n",
    "get_source_cv_and_data = next(tool for tool in tools if tool.__name__ == \"get_source_cv_and_data\")\n",
    "print(f\"\\n2. get_source_cv_and_data('195385'):\")\n",
    "cv_result = get_source_cv_and_data('195385')\n",
    "print(cv_result[:1000] + \"...\" if len(cv_result) > 1000 else cv_result)\n",
    "\n",
    "print(f\"\\n‚úÖ Toolkit limpio con {len(tools)} herramientas:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3ddf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funci√≥n run_agent_with_prompt definida y lista para usar\n"
     ]
    }
   ],
   "source": [
    "# Configurar y ejecutar el agente\n",
    "import asyncio\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "from adk_components.agent_definition import create_report_agent\n",
    "from config import settings\n",
    "\n",
    "async def run_agent_with_prompt(prompt: str):\n",
    "    \"\"\"Ejecuta el agente con un prompt espec√≠fico\"\"\"\n",
    "    agent = create_report_agent(tools)\n",
    "    session_service = InMemorySessionService()\n",
    "    session = await session_service.create_session(\n",
    "        app_name=settings.APP_NAME, user_id=settings.USER_ID\n",
    "    )\n",
    "    runner = Runner(agent=agent, app_name=settings.APP_NAME, session_service=session_service)\n",
    "    content = types.Content(role='user', parts=[types.Part(text=prompt)])\n",
    "    \n",
    "    async for event in runner.run_async(user_id=session.user_id, session_id=session.id, new_message=content):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                return event.content.parts[0].text\n",
    "            return ''\n",
    "    return ''\n",
    "\n",
    "print(\"Funci√≥n run_agent_with_prompt definida y lista para usar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e39396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ EJECUTANDO NUEVO ENFOQUE 'LLM + CVs'...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# PRUEBA DEL NUEVO ENFOQUE \"LLM + CVs\"\n",
    "# El agente ahora usa get_source_cv_and_data() para an√°lisis experto\n",
    "\n",
    "\n",
    "prompt_cv_analysis = f\"\"\"\n",
    "OBJECTIVE: Generate a precise report based solely on CV analysis and real data.\n",
    "\n",
    "AVAILABLE TOOLS (USE ONLY THESE):\n",
    "- list_sources(): general overview of all sources\n",
    "- get_source_cv_and_data(source_id): complete CV and raw data for expert analysis\n",
    "\n",
    "SPECIFIC INSTRUCTIONS:\n",
    "1. USE ONLY list_sources() and get_source_cv_and_data() - DO NOT use other tools\n",
    "2. For EACH source in list_sources(), use get_source_cv_and_data() for complete analysis\n",
    "3. Read each source's CV completely to understand their normal patterns\n",
    "4. Intelligently interpret whether events are normal according to the CV or true incidents\n",
    "5. Determine what day of the week {execution_date} is and verify specific patterns for that day in each CV\n",
    "\n",
    "SPECIAL CASE TO VALIDATE:\n",
    "- Source 195385: Are the files that arrived normal according to its CV?\n",
    "- Is the timing 08:06 UTC within expected windows?\n",
    "- Is lag -1 (Saturday files arriving Sunday) normal according to the CV?\n",
    "\n",
    "CRITICAL RULES FOR ANALYSIS:\n",
    "- If the CV says something is normal, it is NOT an incident\n",
    "- Only report true deviations from CV patterns\n",
    "- Use real record numbers in \"All Good\"\n",
    "- Each source appears only once in the highest severity section\n",
    "- IGNORE \"raw_incidents\" data if it contradicts CV analysis\n",
    "\n",
    "‚ö†Ô∏è CRITICAL RULE ABOUT VOLUME VARIATIONS:\n",
    "- IF VOLUME DECREASE IS CAUSED BY MISSING FILES, DO NOT REPORT VOLUMNE VARIATION!\n",
    "- Only report volume variation if files arrived but with fewer/more rows\n",
    "- Example: If 0 files arrived and 0 rows ‚Üí Only missing files (NOT volume variation)\n",
    "- Example: If 2 files arrived but with 50% fewer rows ‚Üí Volume variation\n",
    "\n",
    "SEVERITY CLASSIFICATION:\n",
    "üî¥ URGENT: Critical missing files according to CV OR 3+ \"needs attention\" incidents\n",
    "üü° NEEDS ATTENTION: Volume deviations, timing outside CV windows\n",
    "üü¢ ALL GOOD: Everything within normal CV patterns\n",
    "\n",
    "GENERATE THE EXECUTIVE REPORT IN ENGLISH for {execution_date}\n",
    "\"\"\"\n",
    "\n",
    "print(\"üöÄ EJECUTANDO NUEVO ENFOQUE 'LLM + CVs'...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "response = await run_agent_with_prompt(prompt_cv_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurate de reejecutar las celdas anteriores para que la nueva fecha sea tomada en cuenta\n",
    "response_1 = await run_agent_with_prompt(prompt_cv_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d5d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = await run_agent_with_prompt(prompt_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52716839",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5efcc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_3vs3(agent_responses, feedback_responses):\n",
    "    \"\"\"\n",
    "    Compara 3 respuestas del agente vs 3 del feedback\n",
    "    \n",
    "    agent_responses = [response_1, response_2, response_3]\n",
    "    feedback_responses = [feedback_sept8, feedback_sept9, feedback_sept10]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä AGENT vs FEEDBACK EVALUATION (3 vs 3)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Comparar cada par (agente vs feedback correspondiente)\n",
    "    for i, (agent_resp, feedback_resp) in enumerate(zip(agent_responses, feedback_responses), 1):\n",
    "        \n",
    "        print(f\"\\nüóìÔ∏è COMPARISON {i}:\")\n",
    "        \n",
    "        # Parsear ambas respuestas\n",
    "        agent_parsed = parse_simple(agent_resp)\n",
    "        feedback_parsed = parse_simple(feedback_resp)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        accuracy = calculate_accuracy(agent_parsed, feedback_parsed)\n",
    "        \n",
    "        # Mostrar detalles\n",
    "        print(f\"  üìà Accuracy: {accuracy:.1%}\")\n",
    "        print(f\"  üî¥ Agent Urgent: {len(agent_parsed['urgent'])} | Feedback: {len(feedback_parsed['urgent'])}\")\n",
    "        print(f\"  üü° Agent Needs Att: {len(agent_parsed['needs_attention'])} | Feedback: {len(feedback_parsed['needs_attention'])}\")\n",
    "        print(f\"  üü¢ Agent All Good: {len(agent_parsed['all_good'])} | Feedback: {len(feedback_parsed['all_good'])}\")\n",
    "        \n",
    "        # Identificar diferencias espec√≠ficas\n",
    "        differences = find_differences(agent_parsed, feedback_parsed)\n",
    "        if differences:\n",
    "            print(f\"  ‚ùå Differences:\")\n",
    "            for diff in differences:\n",
    "                print(f\"    {diff}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Perfect match!\")\n",
    "        \n",
    "        results.append({\n",
    "            'comparison': i,\n",
    "            'accuracy': accuracy,\n",
    "            'differences': differences\n",
    "        })\n",
    "    \n",
    "    # Resumen general\n",
    "    print(f\"\\nüìã OVERALL SUMMARY:\")\n",
    "    avg_accuracy = sum(r['accuracy'] for r in results) / len(results)\n",
    "    print(f\"  üìà Average Accuracy: {avg_accuracy:.1%}\")\n",
    "    \n",
    "        \n",
    "    return results\n",
    "\n",
    "def parse_simple(response_text):\n",
    "    \"\"\"Extrae IDs de fuentes por severidad\"\"\"\n",
    "    import re\n",
    "    \n",
    "    result = {'urgent': [], 'needs_attention': [], 'all_good': []}\n",
    "    \n",
    "    # Patrones m√°s flexibles para ambos formatos\n",
    "    urgent_patterns = [\n",
    "        r'\\*\\s*Urgent Action Required\\*(.*?)(?:\\*\\s*Needs Attention\\*|\\*\\s*No Action Needed\\*|\\*\\s*All Good\\*|$)',\n",
    "        r'Urgent Action Required(.*?)(?:Needs Attention|No Action Needed|All Good|$)'\n",
    "    ]\n",
    "    \n",
    "    needs_patterns = [\n",
    "        r'\\*\\s*Needs Attention\\*(.*?)(?:\\*\\s*All Good\\*|\\*\\s*No Action Needed\\*|$)',\n",
    "        r'Needs Attention(.*?)(?:All Good|No Action Needed|$)'\n",
    "    ]\n",
    "    \n",
    "    good_patterns = [\n",
    "        r'\\*\\s*(?:All Good|No Action Needed)\\*(.*?)$',\n",
    "        r'(?:All Good|No Action Needed)(.*?)$'\n",
    "    ]\n",
    "    \n",
    "    # Buscar secci√≥n URGENT\n",
    "    for pattern in urgent_patterns:\n",
    "        match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            result['urgent'] = re.findall(r'\\(id:\\s*(\\d+)\\)', match.group(1))\n",
    "            break\n",
    "    \n",
    "    # Buscar secci√≥n NEEDS ATTENTION\n",
    "    for pattern in needs_patterns:\n",
    "        match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            result['needs_attention'] = re.findall(r'\\(id:\\s*(\\d+)\\)', match.group(1))\n",
    "            break\n",
    "    \n",
    "    # Buscar secci√≥n ALL GOOD\n",
    "    for pattern in good_patterns:\n",
    "        match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            result['all_good'] = re.findall(r'\\(id:\\s*(\\d+)\\)', match.group(1))\n",
    "            break\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_accuracy(agent_parsed, feedback_parsed):\n",
    "    \"\"\"Calcula precisi√≥n comparando clasificaciones\"\"\"\n",
    "    \n",
    "    # Obtener todas las fuentes mencionadas en ambos\n",
    "    all_sources = set()\n",
    "    for parsed in [agent_parsed, feedback_parsed]:\n",
    "        for sources in parsed.values():\n",
    "            all_sources.update(sources)\n",
    "    \n",
    "    if not all_sources:\n",
    "        return 1.0\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for source_id in all_sources:\n",
    "        # Determinar clasificaci√≥n del agente\n",
    "        agent_severity = None\n",
    "        for severity, sources in agent_parsed.items():\n",
    "            if source_id in sources:\n",
    "                agent_severity = severity\n",
    "                break\n",
    "        \n",
    "        # Determinar clasificaci√≥n del feedback\n",
    "        feedback_severity = None\n",
    "        for severity, sources in feedback_parsed.items():\n",
    "            if source_id in sources:\n",
    "                feedback_severity = severity\n",
    "                break\n",
    "        \n",
    "        # Comparar\n",
    "        if agent_severity == feedback_severity:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(all_sources)\n",
    "\n",
    "def find_differences(agent_parsed, feedback_parsed):\n",
    "    \"\"\"Encuentra diferencias espec√≠ficas\"\"\"\n",
    "    \n",
    "    differences = []\n",
    "    \n",
    "    # Obtener todas las fuentes\n",
    "    all_sources = set()\n",
    "    for parsed in [agent_parsed, feedback_parsed]:\n",
    "        for sources in parsed.values():\n",
    "            all_sources.update(sources)\n",
    "    \n",
    "    for source_id in all_sources:\n",
    "        # Clasificaci√≥n del agente\n",
    "        agent_severity = 'missing'\n",
    "        for severity, sources in agent_parsed.items():\n",
    "            if source_id in sources:\n",
    "                agent_severity = severity\n",
    "                break\n",
    "        \n",
    "        # Clasificaci√≥n del feedback\n",
    "        feedback_severity = 'missing'\n",
    "        for severity, sources in feedback_parsed.items():\n",
    "            if source_id in sources:\n",
    "                feedback_severity = severity\n",
    "                break\n",
    "        \n",
    "        # Si son diferentes\n",
    "        if agent_severity != feedback_severity:\n",
    "            differences.append(f\"Source {source_id}: Agent={agent_severity} vs Feedback={feedback_severity}\")\n",
    "    \n",
    "    return differences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent_responses = [response, response_1, response_2]\n",
    "\n",
    "\n",
    "feedback_responses = [\n",
    "    \"\"\"\n",
    "*Report generated at UTC HOUR*: 23:30 UTC \n",
    "*  Urgent Action Required* \n",
    "‚Ä¢ * _Payments_Layout_1_V3 (id: 220504)* ‚Äì 2025-09-07: 14 files missing past 08:08‚Äì08:18 UTC window ‚Äî entities: Clien_CBK, WhiteLabel, Shop, Google, POC, Market, Innovation, Donation, Beneficios, ApplePay, Anota-ai, AddCard, Clien _payments, ClienX_Clube ? *Action:* Notify provider to generate/re-send; re-run ingestion and verify completeness \n",
    "‚Ä¢ * _Payments_Layout_2_V3 (id: 220505)* ‚Äì 2025-09-07: 2 files missing past 08:02‚Äì08:11 UTC ‚Äî expected: *_Clien _Debito_payments_accounting_report_2025_09_07.csv; *_Clien _MVP_payments_accounting_report_2025_09_07.csv ? *Action:* Notify provider to generate/re-send; re-run ingestion and verify completeness \n",
    "‚Ä¢ * _Payments_Layout_3_V3 (id: 220506)* ‚Äì 2025-09-06: 1 file missing past 08:03‚Äì08:19 UTC ‚Äî expected: [hash]_Clien _3DS_payments_accounting_report_2025_09_06.csv ? *Action:* Notify provider to generate/re-send; re-run ingestion and verify completeness \n",
    "\n",
    "*  Needs Attention* \n",
    "‚Ä¢ * _Settlement_Layout_2 (id: 195385)* ‚Äì 2025-09-08: Saipos file delivered early at 08:06 UTC (usual ~17:20) ‚Äî Confirm schedule change; adjust downstream triggers if needed\n",
    "‚Ä¢ * _Sale_adjustments_3 (id: 239611)* ‚Äì 2025-09-08: ClienX volume 61,639 (> usual Monday 40k‚Äì55k) ‚Äî Confirm coverage/window; monitor next run \n",
    "‚Ä¢ * _STL adjustments_3 (id: 239613)* ‚Äì 2025-09-08: ClienX volume 56,277 (>95% bound 50,211) ‚Äî Validate downstream completed; track if persists ‚Ä¢ * _STL payments_2 (id: 228038)* ‚Äì 2025-09-08: ClienX 1,023,337 (>95% band 869,600) and lag shifted to near-real-time ‚Äî Confirm intentional lag change; keep a short-term volume watch\n",
    "\n",
    "*  No Action Needed* \n",
    "‚Ä¢ *Desco Devolu√ß√µes (id: 211544)* ‚Äì 2025-09-08: `[6,798] records`\n",
    " ‚Ä¢ *Desco   (id: 209773)* ‚Äì 2025-09-08: `[190,541] records` \n",
    "‚Ä¢ *Itm Devolu√ß√£o (id: 224603)* ‚Äì 2025-09-08: `[26,364] records` \n",
    "‚Ä¢ *Itm Pagamentos (id: 224602)* ‚Äì 2025-09-08: `[678,305] records` \n",
    "‚Ä¢ * _Sale payments_2 (id: 228036)* ‚Äì 2025-09-08: `[1,233,496] records` \n",
    "‚Ä¢ *MyPal_Activity report (id: 195439)* ‚Äì 2025-09-08: `[347,476] records`\n",
    " ‚Ä¢ *MyPal_DBR RX (id: 195436)* ‚Äì 2025-09-08: `[0] records` \n",
    "‚Ä¢ *Soop - Tipo 2 (id: 207936)* ‚Äì 2025-09-08: `[4,060] records`\n",
    " ‚Ä¢ *Soop - Tipo 3 (id: 207938)* ‚Äì 2025-09-08: `[4,066] records`\n",
    " ‚Ä¢ *Soop Transaction   3 (id: 199944)* ‚Äì 2025-09-08: `[179,070] records` \n",
    "‚Ä¢ All other recent files appear normal\n",
    "\"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "Report generated at UTC HOUR*: 20:30 \n",
    "*:c√≠rculo_rojo: Urgent Action Required* \n",
    "‚Ä¢ * _Payments_Layout_1_V3 (id: 220504)* ‚Äì 2025-09-10 (acct date 2025_09_09): 14 expected files missing; only 4 arrived (DataOnly, Saipos, Anotaai_Wallet [empty], safemode [empty]). Missing suffixes: *_Clien _CBK_..._2025_09_09.csv, *_Clien _WhiteLabel_..._2025_09_09.csv, *_Clien _Shop_..._2025_09_09.csv, *_Clien _PwGoogle_..._2025_09_09.csv, *_Clien _POC_..._2025_09_09.csv, *_Clien _Market_..._2025_09_09.csv, *_Clien _Innovation_..._2025_09_09.csv, *_Clien _Donation_..._2025_09_09.csv, *_Clien _Beneficios_..._2025_09_09.csv, *_Clien _ApplePay_..._2025_09_09.csv, *_Clien _Anota-ai_..._2025_09_09.csv, *_Clien _AddCard_..._2025_09_09.csv, *_Clien _payments_..._2025_09_09.csv, *_ClienX_Clube_..._2025_09_09.csv ? *Action:* Request re-delivery/backfill for the 14 files; verify the 08:08‚Äì08:18 UTC job and re-ingest if objects exist upstream \n",
    "‚Ä¢ * _Payments_Layout_2_V3 (id: 220505)* ‚Äì 2025-09-10 (acct date 2025_09_09): Expected pair missing. Not present: *_Clien _Debito_payments_accounting_report_2025_09_09.csv, *_Clien _MVP_payments_accounting_report_2025_09_09.csv ? *Action:* Request re-delivery and/or re-run ingestion; check the 08:02‚Äì08:11 UTC schedule and reprocess if files are available upstream ‚Ä¢ * _Payments_Layout_3_V3 (id: 220506)* ‚Äì 2025-09-10: No daily Clien _3DS file; 08:03‚Äì08:19 UTC window missed ? *Action:* Confirm whether today's Clien _3DS report (expected by pattern) was produced; ingest if present upstream or request export and backfill ‚Ä¢ * _Settlement_Layout_1 (id: 196125)* ‚Äì 2025-09-10 (settlement date 2025-09-09): No files uploaded; entire morning drop (08:04‚Äì08:12 UTC) absent ? *Action:* Re-trigger the scheduled ingestion; confirm upstream generation and request re-delivery; backfill upon receipt \n",
    "‚Ä¢ * _Settlement_Layout_2 (id: 195385)* ‚Äì 2025-09-10 (settlement date 2025-09-09): Major shortfall‚Äîonly 7 files (DataOnly 4; Saipos 3) vs typical 32‚Äì41; categories not present today: Clube, Donation, Shop, WhiteLabel, CBK, Beneficios, Anota-ai ? *Action:* Escalate to provider/ops; check upstream listings and re-ingest or request re-export for the absent categories \n",
    "\n",
    "*:c√≠rculo_amarillo_grande: Needs Attention* \n",
    "\n",
    "*:c√≠rculo_verde_grande: No Action Needed* \n",
    "‚Ä¢ *Desco Devolu√ß√µes (id: 211544)* ‚Äì 2025-09-10: `[5322] records` \n",
    "‚Ä¢ *Desco   (id: 209773)* ‚Äì 2025-09-10: `[156356] records` \n",
    "‚Ä¢ *Itm Devolu√ß√£o (id: 224603)* ‚Äì 2025-09-10: `[18612] records` \n",
    "‚Ä¢ *Itm Pagamentos (id: 224602)* ‚Äì 2025-09-10: `[488161] records`\n",
    "‚Ä¢ * _Sale payments_2 (id: 228036)* ‚Äì 2025-09-10: `[295257] records` \n",
    "‚Ä¢ * _Sale_adjustments_3 (id: 239611)* ‚Äì 2025-09-10: `[15292] records` \n",
    "‚Ä¢ * _STL adjustments_3 (id: 239613)* ‚Äì 2025-09-10: `[13642] records` \n",
    "‚Ä¢ * _STL payments_2 (id: 228038)* ‚Äì 2025-09-10: `[239383] records` \n",
    "‚Ä¢ *MyPal_Activity report (id: 195439)* ‚Äì 2025-09-10: `[386320] records` \n",
    "‚Ä¢ *MyPal_DBR RX (id: 195436)* ‚Äì 2025-09-10: `[206708] records` \n",
    "‚Ä¢ *Soop - Tipo 2 (id: 207936)* ‚Äì 2025-09-10: `[4986] records` \n",
    "‚Ä¢ *Soop - Tipo 3 (id: 207938)* ‚Äì 2025-09-10: `[5207] records`\n",
    "‚Ä¢ *Soop Transaction   3 (id: 199944)* ‚Äì 2025-09-10: `[113926] records` \n",
    "‚Ä¢ All other recent files appear normal\"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "Report generated at UTC HOUR*: 20:30 \n",
    "*:c√≠rculo_rojo: Urgent Action Required* \n",
    "‚Ä¢ * _Payments_Layout_1_V3 (id: 220504)* ‚Äì 2025-09-10 (acct date 2025_09_09): 14 expected files missing; only 4 arrived (DataOnly, Saipos, Anotaai_Wallet [empty], safemode [empty]). Missing suffixes: *_Clien _CBK_..._2025_09_09.csv, *_Clien _WhiteLabel_..._2025_09_09.csv, *_Clien _Shop_..._2025_09_09.csv, *_Clien _PwGoogle_..._2025_09_09.csv, *_Clien _POC_..._2025_09_09.csv, *_Clien _Market_..._2025_09_09.csv, *_Clien _Innovation_..._2025_09_09.csv, *_Clien _Donation_..._2025_09_09.csv, *_Clien _Beneficios_..._2025_09_09.csv, *_Clien _ApplePay_..._2025_09_09.csv, *_Clien _Anota-ai_..._2025_09_09.csv, *_Clien _AddCard_..._2025_09_09.csv, *_Clien _payments_..._2025_09_09.csv, *_ClienX_Clube_..._2025_09_09.csv ? *Action:* Request re-delivery/backfill for the 14 files; verify the 08:08‚Äì08:18 UTC job and re-ingest if objects exist upstream \n",
    "‚Ä¢ * _Payments_Layout_2_V3 (id: 220505)* ‚Äì 2025-09-10 (acct date 2025_09_09): Expected pair missing. Not present: *_Clien _Debito_payments_accounting_report_2025_09_09.csv, *_Clien _MVP_payments_accounting_report_2025_09_09.csv ? *Action:* Request re-delivery and/or re-run ingestion; check the 08:02‚Äì08:11 UTC schedule and reprocess if files are available upstream ‚Ä¢ * _Payments_Layout_3_V3 (id: 220506)* ‚Äì 2025-09-10: No daily Clien _3DS file; 08:03‚Äì08:19 UTC window missed ? *Action:* Confirm whether today's Clien _3DS report (expected by pattern) was produced; ingest if present upstream or request export and backfill ‚Ä¢ * _Settlement_Layout_1 (id: 196125)* ‚Äì 2025-09-10 (settlement date 2025-09-09): No files uploaded; entire morning drop (08:04‚Äì08:12 UTC) absent ? *Action:* Re-trigger the scheduled ingestion; confirm upstream generation and request re-delivery; backfill upon receipt \n",
    "‚Ä¢ * _Settlement_Layout_2 (id: 195385)* ‚Äì 2025-09-10 (settlement date 2025-09-09): Major shortfall‚Äîonly 7 files (DataOnly 4; Saipos 3) vs typical 32‚Äì41; categories not present today: Clube, Donation, Shop, WhiteLabel, CBK, Beneficios, Anota-ai ? *Action:* Escalate to provider/ops; check upstream listings and re-ingest or request re-export for the absent categories \n",
    "\n",
    "*:c√≠rculo_amarillo_grande: Needs Attention* \n",
    "\n",
    "*:c√≠rculo_verde_grande: No Action Needed* \n",
    "‚Ä¢ *Desco Devolu√ß√µes (id: 211544)* ‚Äì 2025-09-10: `[5322] records` \n",
    "‚Ä¢ *Desco   (id: 209773)* ‚Äì 2025-09-10: `[156356] records` \n",
    "‚Ä¢ *Itm Devolu√ß√£o (id: 224603)* ‚Äì 2025-09-10: `[18612] records` \n",
    "‚Ä¢ *Itm Pagamentos (id: 224602)* ‚Äì 2025-09-10: `[488161] records`\n",
    "‚Ä¢ * _Sale payments_2 (id: 228036)* ‚Äì 2025-09-10: `[295257] records` \n",
    "‚Ä¢ * _Sale_adjustments_3 (id: 239611)* ‚Äì 2025-09-10: `[15292] records` \n",
    "‚Ä¢ * _STL adjustments_3 (id: 239613)* ‚Äì 2025-09-10: `[13642] records` \n",
    "‚Ä¢ * _STL payments_2 (id: 228038)* ‚Äì 2025-09-10: `[239383] records` \n",
    "‚Ä¢ *MyPal_Activity report (id: 195439)* ‚Äì 2025-09-10: `[386320] records` \n",
    "‚Ä¢ *MyPal_DBR RX (id: 195436)* ‚Äì 2025-09-10: `[206708] records` \n",
    "‚Ä¢ *Soop - Tipo 2 (id: 207936)* ‚Äì 2025-09-10: `[4986] records` \n",
    "‚Ä¢ *Soop - Tipo 3 (id: 207938)* ‚Äì 2025-09-10: `[5207] records`\n",
    "‚Ä¢ *Soop Transaction   3 (id: 199944)* ‚Äì 2025-09-10: `[113926] records` \n",
    "‚Ä¢ All other recent files appear normal\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4b369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AGENT vs FEEDBACK EVALUATION (3 vs 3)\n",
      "==================================================\n",
      "\n",
      "üóìÔ∏è COMPARISON 1:\n",
      "  üìà Accuracy: 66.7%\n",
      "  üî¥ Agent Urgent: 8 | Feedback: 3\n",
      "  üü° Agent Needs Att: 1 | Feedback: 4\n",
      "  üü¢ Agent All Good: 11 | Feedback: 10\n",
      "  ‚ùå Differences:\n",
      "    Source 228036: Agent=urgent vs Feedback=all_good\n",
      "    Source 196125: Agent=urgent vs Feedback=missing\n",
      "    Source 239613: Agent=urgent vs Feedback=needs_attention\n",
      "    Source 195385: Agent=all_good vs Feedback=needs_attention\n",
      "    Source 228038: Agent=urgent vs Feedback=needs_attention\n",
      "    Source 239611: Agent=urgent vs Feedback=needs_attention\n",
      "\n",
      "üóìÔ∏è COMPARISON 2:\n",
      "  üìà Accuracy: 38.9%\n",
      "  üî¥ Agent Urgent: 8 | Feedback: 5\n",
      "  üü° Agent Needs Att: 3 | Feedback: 0\n",
      "  üü¢ Agent All Good: 8 | Feedback: 13\n",
      "  ‚ùå Differences:\n",
      "    Source 207936: Agent=urgent vs Feedback=all_good\n",
      "    Source 228036: Agent=urgent vs Feedback=all_good\n",
      "    Source 220505: Agent=needs_attention vs Feedback=urgent\n",
      "    Source 239613: Agent=urgent vs Feedback=all_good\n",
      "    Source 220506: Agent=needs_attention vs Feedback=urgent\n",
      "    Source 195385: Agent=all_good vs Feedback=urgent\n",
      "    Source 199944: Agent=urgent vs Feedback=all_good\n",
      "    Source 228038: Agent=urgent vs Feedback=all_good\n",
      "    Source 239611: Agent=urgent vs Feedback=all_good\n",
      "    Source 207938: Agent=urgent vs Feedback=all_good\n",
      "    Source 220504: Agent=needs_attention vs Feedback=urgent\n",
      "\n",
      "üóìÔ∏è COMPARISON 3:\n",
      "  üìà Accuracy: 72.2%\n",
      "  üî¥ Agent Urgent: 8 | Feedback: 5\n",
      "  üü° Agent Needs Att: 3 | Feedback: 0\n",
      "  üü¢ Agent All Good: 10 | Feedback: 13\n",
      "  ‚ùå Differences:\n",
      "    Source 228036: Agent=urgent vs Feedback=all_good\n",
      "    Source 239613: Agent=urgent vs Feedback=all_good\n",
      "    Source 195385: Agent=needs_attention vs Feedback=urgent\n",
      "    Source 228038: Agent=urgent vs Feedback=all_good\n",
      "    Source 239611: Agent=urgent vs Feedback=all_good\n",
      "\n",
      "üìã OVERALL SUMMARY:\n",
      "  üìà Average Accuracy: 59.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'comparison': 1,\n",
       "  'accuracy': 0.6666666666666666,\n",
       "  'differences': ['Source 228036: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 196125: Agent=urgent vs Feedback=missing',\n",
       "   'Source 239613: Agent=urgent vs Feedback=needs_attention',\n",
       "   'Source 195385: Agent=all_good vs Feedback=needs_attention',\n",
       "   'Source 228038: Agent=urgent vs Feedback=needs_attention',\n",
       "   'Source 239611: Agent=urgent vs Feedback=needs_attention']},\n",
       " {'comparison': 2,\n",
       "  'accuracy': 0.3888888888888889,\n",
       "  'differences': ['Source 207936: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 228036: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 220505: Agent=needs_attention vs Feedback=urgent',\n",
       "   'Source 239613: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 220506: Agent=needs_attention vs Feedback=urgent',\n",
       "   'Source 195385: Agent=all_good vs Feedback=urgent',\n",
       "   'Source 199944: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 228038: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 239611: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 207938: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 220504: Agent=needs_attention vs Feedback=urgent']},\n",
       " {'comparison': 3,\n",
       "  'accuracy': 0.7222222222222222,\n",
       "  'differences': ['Source 228036: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 239613: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 195385: Agent=needs_attention vs Feedback=urgent',\n",
       "   'Source 228038: Agent=urgent vs Feedback=all_good',\n",
       "   'Source 239611: Agent=urgent vs Feedback=all_good']}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_3vs3(agent_responses, feedback_responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_detection_p_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
