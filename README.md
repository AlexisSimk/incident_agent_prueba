# Agent Factory - Incident Detection System
<img width="1024" height="1024" alt="Diagram" src="https://github.com/user-attachments/assets/8fcf7697-10cd-429a-9858-8aceb643b21e" />

Un sistema de detecciÃ³n de incidencias basado en agentes LLM para monitoreo de fuentes de datos diarias.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un agente inteligente que analiza automÃ¡ticamente las fuentes de datos diarias, detecta incidencias y genera reportes ejecutivos. El agente utiliza CVs (Curriculum Vitae) de las fuentes para entender patrones normales y distinguir entre comportamientos esperados e incidencias reales.

### ğŸ¯ Funcionalidades Principales

- **DetecciÃ³n automÃ¡tica de incidencias**: Missing files, volume variations, timing issues, etc.
- **AnÃ¡lisis basado en CVs**: Interpreta documentos de patrones histÃ³ricos para determinar normalidad
- **Reportes ejecutivos**: Clasifica incidencias por severidad (URGENT, NEEDS ATTENTION, ALL GOOD)
- **Soporte multi-modelo**: Compatible con OpenAI GPT y Google Gemini
- **AnÃ¡lisis inteligente**: El LLM actÃºa como protagonista en la toma de decisiones

## ğŸ—ï¸ Arquitectura del Sistema

```
agent_factory/
â”œâ”€â”€ adk_components/          # DefiniciÃ³n del agente ADK
â”œâ”€â”€ config/                  # ConfiguraciÃ³n del sistema
â”œâ”€â”€ data_processing/         # Carga y consolidaciÃ³n de datos
â”œâ”€â”€ report_builder/          # Herramientas del agente
â”œâ”€â”€ datos/                   # Datos de entrada (no incluido)
â”œâ”€â”€ notebooks/               # AnÃ¡lisis y desarrollo
â”œâ”€â”€ reportes_generados/      # Reportes generados por el agente
â””â”€â”€ main.py                  # Punto de entrada principal
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Requisitos

```bash
pip install -r requirements.txt
```

### 2. ConfiguraciÃ³n del Entorno

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
# API Keys (configura al menos una)
OPENAI_API_KEY=tu_openai_api_key_aqui
GOOGLE_API_KEY=tu_google_api_key_aqui

# Modelo a utilizar
AGENT_MODEL=gpt-4o-mini
# Opciones: gpt-4o, gpt-4o-mini, gpt-4-turbo, gemini-2.0-flash, gemini-1.5-pro

# Rutas de datos (opcional - usa defaults si no se especifica)
DATA_BASE_PATH=./datos
DATA_CV_PATH=./datos/cv
DATA_DAILY_PATH=./datos/daily_files
DATA_FEEDBACK_PATH=./datos/feedback

# ConfiguraciÃ³n del agente (opcional)
APP_NAME=incident_detection_agent
USER_ID=ops_team
```

### 3. Estructura de Datos

Crea la siguiente estructura de carpetas y coloca tus datos:

```
datos/
â”œâ”€â”€ cv/                      # CVs de las fuentes (*.md)
â”‚   â”œâ”€â”€ 195385_native.md
â”‚   â”œâ”€â”€ 220504_native.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ daily_files/             # Archivos diarios
â”‚   â””â”€â”€ 2025-09-08_20_00_UTC/
â”‚       â”œâ”€â”€ files.json
â”‚       â””â”€â”€ files_last_weekday.json
â””â”€â”€ feedback/                # RetroalimentaciÃ³n (para V2)
    â””â”€â”€ Feedback - week 9 sept.csv

reportes_generados/          # Reportes del agente (subidos manualmente)
â””â”€â”€ (reportes generados con modelo gpt-4.1)
```

## ğŸ“– Uso del Sistema

### EjecuciÃ³n BÃ¡sica

```bash
python main.py --date 2025-09-08
```

### Desarrollo y AnÃ¡lisis

Para desarrollo y anÃ¡lisis detallado, utiliza el notebook:

```bash
jupyter notebook notebooks/v1_analysis.ipynb
```

### Ejemplo de Salida

```
ğŸ¤– Using model: gpt-4.1

*Report generated at UTC HOUR*: 16:00 UTC

*  Urgent Action Required*
â€¢ *__Payments_Layout_1_V3 (id: 220504)* â€“ 2025-09-08: 12 files missing past 08:08â€“08:18 UTC
â€¢ *_Settlement_Layout_1 (id: 196125)* â€“ 2025-09-08: 2 files missing past 08:00â€“08:00 UTC

*  Needs Attention*
â€¢ *_Settlement_Layout_2 (id: 195385)* â€“ 2025-09-08: Early delivery at 08:06 UTC

*  All Good*
â€¢ *MyPal_DBR RX (id: 195436)* â€“ 2025-09-08: [347,476] records
â€¢ *Soop Transaction PIX 3 (id: 199944)* â€“ 2025-09-08: [179,070] records
```

## ğŸ”§ Componentes Principales

### 1. Detectores de Incidencias

- **Missing File Detector**: Archivos esperados pero no recibidos
- **Volume Variation Detector**: Cambios anÃ³malos en volumen de datos
- **Schedule Detector**: Archivos fuera de horario esperado
- **Duplicated/Failed File Detector**: Archivos duplicados o con errores
- **Empty File Detector**: Archivos vacÃ­os inesperados
- **Historical Upload Detector**: Archivos de perÃ­odos anteriores

### 2. Herramientas del Agente

- `list_sources()`: Panorama general de todas las fuentes
- `get_source_cv_and_data(source_id)`: CV completo y datos para anÃ¡lisis
- `get_execution_date_info()`: InformaciÃ³n del dÃ­a de la semana

### 3. Criterios de Severidad

- **ğŸ”´ URGENT**: Missing files crÃ­ticos o 3+ incidentes "needs attention"
- **ğŸŸ¡ NEEDS ATTENTION**: Volume variations, timing issues
- **ğŸŸ¢ ALL GOOD**: Sin incidentes segÃºn patrones del CV

## âš ï¸ Limitaciones Conocidas

### 1. ValidaciÃ³n de Resultados
- **No implementado**: Sistema de validaciÃ³n automÃ¡tica de resultados
- **Impacto**: Requiere validaciÃ³n manual de la precisiÃ³n del agente
- **MitigaciÃ³n**: RevisiÃ³n manual de clasificaciones y detecciones

### 2. EvaluaciÃ³n de Performance
- **No implementado**: MÃ©tricas de precisiÃ³n, recall, F1-score
- **Impacto**: Dificulta la mediciÃ³n objetiva de mejoras
- **MitigaciÃ³n**: EvaluaciÃ³n cualitativa caso por caso


### 4. Manejo de Errores
- **LimitaciÃ³n**: Manejo bÃ¡sico de errores en carga de datos
- **Impacto**: Fallos silenciosos si faltan archivos o CVs
- **MitigaciÃ³n**: VerificaciÃ³n manual de estructura de datos

## ğŸ”„ Mejoras Futuras (V2)

### 1. Sistema de EvaluaciÃ³n
- Implementar pipeline de validaciÃ³n automÃ¡tica
- MÃ©tricas de performance (precisiÃ³n, recall)
- Sistema de benchmarking y testing automatizado

### 2. RetroalimentaciÃ³n Continua
- IntegraciÃ³n del archivo de feedback
- Aprendizaje iterativo basado en correcciones
- Ajuste automÃ¡tico de thresholds

### 3. Robustez del Sistema
- Mejor manejo de errores y excepciones
- ValidaciÃ³n de integridad de datos
- Logging detallado para debugging

### 4. OptimizaciÃ³n de Performance
- Cache de CVs para mÃºltiples ejecuciones
- ParalelizaciÃ³n de anÃ¡lisis por fuente
- OptimizaciÃ³n de prompts para consistencia

## ğŸ› ï¸ Desarrollo

### Estructura del CÃ³digo

- **`main.py`**: Punto de entrada principal
- **`adk_components/`**: DefiniciÃ³n del agente y configuraciÃ³n
- **`data_processing/`**: LÃ³gica de carga y procesamiento de datos
- **`report_builder/`**: Herramientas y funciones del agente
- **`config/`**: ConfiguraciÃ³n centralizada del sistema

### Agregar Nuevos Detectores

1. Implementar funciÃ³n en `data_processing/incident_consolidator.py`
2. Agregar llamada en `build_dataset()`
3. Actualizar instrucciones del agente si es necesario

### Cambiar Modelos LLM

Simplemente actualiza `AGENT_MODEL` en tu `.env`:
- OpenAI: `gpt-4.1`, `gpt-4.1-mini`, `gpt-4o`
- Gemini: `gemini-2.5-flash`

## ğŸ“Š Casos de Uso

### 1. Monitoreo Diario
Ejecutar automÃ¡ticamente cada maÃ±ana para detectar incidencias del dÃ­a anterior.

### 2. AnÃ¡lisis Retrospectivo
Analizar perÃ­odos histÃ³ricos para identificar patrones de incidencias.

### 3. ValidaciÃ³n de Cambios
Verificar el impacto de cambios en sistemas upstream en la calidad de datos.

### 4. AnÃ¡lisis de Reportes
Los reportes generados con modelo gpt-4.1 se almacenan en `reportes_generados/` para:
- Documentar resultados del agente
- Validar consistencia de detecciones
- Mantener historial de anÃ¡lisis para casos especÃ­ficos

## ğŸ¤ ContribuciÃ³n

Este proyecto fue desarrollado como una prueba tÃ©cnica demostrando:
- ImplementaciÃ³n de agentes LLM con Google ADK
- Procesamiento inteligente de datos no estructurados
- AnÃ¡lisis automatizado de patrones y anomalÃ­as
- IntegraciÃ³n de mÃºltiples modelos LLM

## ğŸ“„ Licencia

Proyecto de demostraciÃ³n tÃ©cnica.
